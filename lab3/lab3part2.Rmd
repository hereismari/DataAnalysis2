---
title: "AD2 2016.2 - Lab3 - Parte 2"
author: "Marianne Linhares"
date: "20 de fevereiro de 2016"
output: 
    html_document:
      toc: true
      toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, set.seed(825))

library(dplyr)
library(reshape2)
library(GGally)
library(ggplot2)
library(corrplot)
library(caret)

```

# Bibliotecas Utlizadas

Primeiramente vamos importar as bibliotecas necessárias para esse script ser executado.

``` {r eval=FALSE, echo=TRUE}

library(dplyr)
library(reshape2)
library(GGally)
library(ggplot2)
library(corrplot)
library(caret)

```

# Descrição da atividade

Nessa etapa você vai aplicar os algoritmos de classificação vistos até agora para prever evasão de alunos no curso de computação.

O cenário é o seguinte: o(a) aluno(a) cursou o primeiro período inteiro e queremos prever se ele(a) se matriculará ou não no segundo período. Se ele(a) não se matriculou é porque abandonou o curso ou solicitou desligamento. De forma mais específica:

1. Separe os dados em treino e teste;
2. Uso como atributos as médias das disciplinas mais o atributo que você criou na parte 1 (fique a vontade para criar mais atributos);
3. Treine modelos de regressão logística;
4. Treine modelos de árvore de decisão;
5. Interprete os coeficientes da regressão. Quais atributos parecem ser mais importantes?;
6. Reporte acurácia, precision e recall no treino e teste. Como você avalia os resultados? Justifique sua resposta.

Note que para os passos acima não é necessário usar validação cruzada.

7. Controle overfitting usando validação-cruzada (ridge e lasso na regressão logística e condições de "early stopping" nas árvores de decisão, por exemplo, profundidade da árvore);
8. Reporte acurácia, precision e recall da validação-cruzada e teste (para os melhores modelos);
9. Aplique o melhor modelo a você mesmo(a) usando seu histórico e reporte a predição e resultado.

# 0. Funções auxiliares e variáveis glocais

Para preparar/transformar os dados foram usadas as funções e variáveis apresentadas nesta seção.

``` {r}

COL_DADOS = c("matricula", "cod_disciplina", "disciplina", "ano", "periodo", "media", "evadiu")

COL_T = c("matricula", "AV", "C1", "IC", "LP1", "LPT", "P1", "evadiu", "ano", "periodo")

NOTA_REP = 5
NOTA_FINAL = 7

INICIO_DISC = 2
FIM_DISC = 7
NUM_DISC = 6

select_treino <- function(ano_periodo) {
  return(as.integer(ano_periodo) >= 20091  & as.integer(ano_periodo) <= 20142)
}

decide_na <- function(col, num, media) {
  return(ifelse(is.na(col), ifelse(num > 3, 0, media), col))
}

calcula_status <- function(C1, AV, IC, LP1, LPT, P1) {
  return (
    (C1 < NOTA_REP) & (AV < NOTA_REP) & (IC < NOTA_REP) & (LP1 < NOTA_REP) & 
    (LPT < NOTA_REP) & (P1 < NOTA_REP)
  )
}

calcula_cra <- function(C1, AV, IC, LP1, LPT, P1) {
  return(mean(c(C1, AV, IC, LP1, LPT, P1)))
}

calcula_cra_cc <- function(IC, LP1, P1) {
  return(mean(c(IC, LP1, P1)))
}

calcula_num_finais <- function(C1, AV, IC, LP1, LPT, P1) {
  return(
    (C1 < NOTA_FINAL) + (AV < NOTA_FINAL) + (IC < NOTA_FINAL) + (LP1 < NOTA_FINAL) + 
    (LPT < NOTA_FINAL) + (P1 < NOTA_FINAL)
  )
}

calcula_num_NA <- function(C1, AV, IC, LP1, LPT, P1) {
  return( 
    NUM_DISC - (is.finite(C1) + is.finite(AV) + is.finite(IC) + is.finite(LP1) + 
    is.finite(LPT) + is.finite(P1))
  )
}

decide_na <- function(col, num, media) {
  return(ifelse(is.na(col), ifelse(num > 3, 0, media), col))
}

```

# 1. Separe os dados em treino e teste

Aqui iremos transformar os dados, adicionando também os atributos criados na parte 1.

##  1.1 Separando os dados de treino e teste

Para separar iremos considerar os dados de [2009.1, 2015.1] como treino e 2015.2 como teste. Os demais anos foram retirados pois vários não apresentaram evasões e portanto retirá-los desfaz um pouco o desbalanceamento dos dados (Iremos tratar o desbalanceamento dos dados no final desta atividade na Seção 10) .

``` {r eval=TRUE, echo=TRUE}

dados <- read.csv('~/DataAnalysis2/lab3/treino.csv')
dados <- na.omit(dados)

colnames(dados) <- COL_DADOS

dados$ano_periodo <- paste(as.character(dados$ano), as.character(dados$periodo), sep="")
dados <- dados %>% mutate(treino=select_treino(ano_periodo))

aux_split <- split(dados, dados$treino)

teste <- aux_split[[1]]
teste <- teste[teste$ano == 2015,] # anos abaixo de 2009 nao devem ser considerados

treino <- aux_split[[2]]
```

## 1.2 Transformando as linhas em colunas para facilitar o treinamento do modelo

``` {r eval=TRUE, echo=TRUE}

# Treino

alunos.evadiu <- treino %>%
  group_by(matricula) %>% select(matricula, evadiu, ano, periodo) %>% unique()

treino <- treino %>%
  group_by(matricula, disciplina) %>%
  ungroup() %>%
  select(matricula, disciplina, media) %>%
  mutate(disciplina = as.factor(gsub(" ", ".", disciplina))) %>%
  dcast(matricula ~ disciplina, mean) %>% merge(alunos.evadiu)

colnames(treino) <- COL_T

# Teste

alunos.evadiu <- teste %>%
  group_by(matricula) %>% select(matricula, evadiu, ano, periodo) %>% unique()

teste <- teste %>%
  group_by(matricula, disciplina) %>%
  ungroup() %>%
  select(matricula, disciplina, media) %>%
  mutate(disciplina = as.factor(gsub(" ", ".", disciplina))) %>%
  dcast(matricula ~ disciplina, mean) %>% merge(alunos.evadiu)

colnames(teste) <- COL_T

```

## 1.3 Tratando NAs

Os NAs serão tratados da seguinte forma:

  * Será criada uma nova coluna contendo o número de NAs por linha. Tal coluna poderá ser utilizada como parâmetro para a classificação já que é notável o número de NAs nos alunos que evadem, provavelmente por diferentes motivos (evasão no meio do período, perder a disciplina por falta, etc.)
  
  * Depois disso se o número de NAs for > 3 então substuiremos os NAs por 0, caso contrário os substiruiremos pela média das notas presentes

``` {r}

treino$num_NA <- 
  calcula_num_NA(treino$C1, treino$AV, treino$IC, treino$LP1, treino$LPT, treino$P1)
treino$media_NA <- 
  rowMeans(subset(treino, select = c(C1, AV, IC, LP1, LPT, P1)), na.rm = TRUE)

for (i in INICIO_DISC:FIM_DISC) {
  treino[, i] <- decide_na(treino[, i], treino$num_NA, treino$media_NA)
}

teste$num_NA <- calcula_num_NA(teste$C1, teste$AV, teste$IC, teste$LP1, teste$LPT, teste$P1)
teste$media_NA <- rowMeans(subset(teste, select = c(C1, AV, IC, LP1, LPT, P1)), na.rm = TRUE)

for (i in INICIO_DISC:FIM_DISC) {
  teste[, i] <- decide_na(teste[, i], teste$num_NA, teste$media_NA)
}

```

## 1.4 Adicionando mais atributos

Iremos adicionar as variáveis utilizadas na parte 1 da atividade, de modo que após essas transformações os dados de treino e teste terão a seguinte estrutura e estarão prontos para serem usados para gerar/testar modelos:

  # TODO


``` {r}

# Treino

treino$status <- 
  calcula_status(treino$C1, treino$AV, treino$IC, treino$LP1, treino$LPT, treino$P1)

treino$cra <-
  calcula_cra(treino$C1, treino$AV, treino$IC, treino$LP1, treino$LPT, treino$P1)

treino$cra_cc <- 
  calcula_cra_cc(treino$IC, treino$LP1, treino$P1)

treino$num_finais <- 
  calcula_num_finais(treino$C1, treino$AV, treino$IC, treino$LP1, treino$LPT, treino$P1)

# Teste

teste$status <- 
  calcula_status(teste$C1, teste$AV, teste$IC, teste$LP1, teste$LPT, teste$P1)

teste$cra <-
  calcula_cra(teste$C1, teste$AV, teste$IC, teste$LP1, teste$LPT, teste$P1)

teste$cra_cc <- 
  calcula_cra_cc(teste$IC, teste$LP1, teste$P1)

teste$num_finais <- 
  calcula_num_finais(teste$C1, teste$AV, teste$IC, teste$LP1, teste$LPT, teste$P1)

```

## 1.5 Verificando desbalenceamento no treino

a # TODO

``` {r eval=TRUE, echo=TRUE}

num_evasoes <- treino %>% group_by(ano, periodo) %>%
               summarise(num_evasoes = sum(evadiu),
                         num_alunos = n(), 
                         proporcao = num_evasoes / num_alunos)

soma_evasoes <- num_evasoes %>% ungroup() %>% summarise(total = sum(num_alunos), evasoes = sum(num_evasoes))

# gráfico
soma_evasoes.melt <- soma_evasoes %>% melt()
ggplot(soma_evasoes.melt, aes(x = factor(variable), y = value)) + geom_bar(stat="identity") +  geom_text(aes(label= value), vjust=0) + xlab("") + ylab("Número de alunos")

```


``` {r}

treino$evadiu <- factor(treino$evadiu)
teste$evadiu <- factor(teste$evadiu)

glm.fit <- train(evadiu ~ . -matricula,
                 data=treino,
                 method="glm",
                 family="binomial",
                 na.action = na.omit)

result <- predict(glm.fit, newdata=teste)

confusionMatrix(glm.fit, newdata=teste)

accuracy <- table(result, teste$evadiu)
sum(diag(accuracy))/sum(accuracy)

```

# Referências

[1. practical-guide-deal-imbalanced-classification-problems](https://w...content-available-to-author-only...a.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/)

[2. Exploiting Academic Records for Predicting Student Drop Out](https://s...content-available-to-author-only...g.br/index.php/jidm/article/view/1625/2936)

[3. Informações diversas](https://r...content-available-to-author-only...s.com/ryankelly/reg)
